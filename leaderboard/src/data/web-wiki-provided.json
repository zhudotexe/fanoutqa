[{"acc": {"loose": 0.5456098545791228, "strict": 0.143646408839779}, "rouge": {"rouge1": {"precision": 0.4725312298278398, "recall": 0.6085356260042157, "fscore": 0.49998452049151393}, "rouge2": {"precision": 0.2815675162719931, "recall": 0.35623992580949976, "fscore": 0.3005037957568856}, "rougeL": {"precision": 0.38835972782295014, "recall": 0.5045559933909823, "fscore": 0.41272370572817085}}, "bleurt": 0.5298143146528723, "gpt": 0.30386740331491713, "name": "GPT-4", "authors": "OpenAI", "url": "https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo", "citation": "OpenAI, 2023", "type": "FOUNDATION", "context": 8192}, {"acc": {"loose": 0.6281475667110468, "strict": 0.1919889502762431}, "rouge": {"rouge1": {"precision": 0.6321127734126731, "recall": 0.6764341478682872, "fscore": 0.6144612886380147}, "rouge2": {"precision": 0.3984152059157445, "recall": 0.4292697483707228, "fscore": 0.39470073987610177}, "rougeL": {"precision": 0.536314082392947, "recall": 0.5794550216005496, "fscore": 0.5226280415927149}}, "bleurt": 0.5809288421923614, "gpt": 0.4129834254143646, "name": "GPT-4-turbo", "authors": "OpenAI", "url": "https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo", "citation": "OpenAI, 2023", "type": "FOUNDATION", "context": 128000}, {"acc": {"loose": 0.5165072478945334, "strict": 0.10220994475138122}, "rouge": {"rouge1": {"precision": 0.463516335636312, "recall": 0.5689152894435296, "fscore": 0.45546862566608826}, "rouge2": {"precision": 0.24946325633429448, "recall": 0.31371309343477694, "fscore": 0.25221468710915207}, "rougeL": {"precision": 0.3653434458264324, "recall": 0.45283802498465286, "fscore": 0.3581738799002991}}, "bleurt": 0.49659434195546154, "gpt": 0.2430939226519337, "name": "GPT-3.5-turbo", "authors": "OpenAI", "url": "https://platform.openai.com/docs/models/gpt-3-5-turbo", "citation": "OpenAI, 2023", "type": "FOUNDATION", "context": 16384}, {"acc": {"loose": 0.5143679183027113, "strict": 0.07734806629834254}, "rouge": {"rouge1": {"precision": 0.3407245588154435, "recall": 0.5902473705256917, "fscore": 0.3762628122180759}, "rouge2": {"precision": 0.1832699274716267, "recall": 0.31368060953904164, "fscore": 0.20593914103223815}, "rougeL": {"precision": 0.27518702361418795, "recall": 0.4795536695039635, "fscore": 0.30410024296144206}}, "bleurt": 0.47221096980678773, "gpt": 0.16160220994475138, "name": "LLaMA 2 70B", "authors": "Meta", "url": "https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/", "citation": "Touvron et al., 2023", "type": "FOUNDATION", "context": 4096}, {"acc": {"loose": 0.539846654625103, "strict": 0.08839779005524862}, "rouge": {"rouge1": {"precision": 0.25362992874397977, "recall": 0.6206499844406299, "fscore": 0.3300987746835614}, "rouge2": {"precision": 0.13136173541137755, "recall": 0.31550366270027114, "fscore": 0.17182351464162274}, "rougeL": {"precision": 0.20309078966310257, "recall": 0.5001600255631405, "fscore": 0.2639495371227864}}, "bleurt": 0.4745529419974069, "gpt": 0.20165745856353592, "name": "Mistral-7B", "authors": "Mistral AI", "url": "https://mistral.ai/news/announcing-mistral-7b/", "citation": "Jiang et al., 2023", "type": "FOUNDATION", "context": 32000}, {"acc": {"loose": 0.5760681994469418, "strict": 0.13535911602209943}, "rouge": {"rouge1": {"precision": 0.337280859260002, "recall": 0.6511326541771959, "fscore": 0.40933745120007703}, "rouge2": {"precision": 0.1943735281050035, "recall": 0.3485360713472991, "fscore": 0.23141031987255675}, "rougeL": {"precision": 0.282396718505277, "recall": 0.5503517413117182, "fscore": 0.34298526601178303}}, "bleurt": 0.508856576296259, "gpt": 0.28314917127071826, "name": "Mixtral-8x7B", "authors": "Mistral AI", "url": "https://mistral.ai/news/mixtral-of-experts/", "citation": "Jiang et al., 2024", "type": "FOUNDATION", "context": 32000}, {"acc": {"loose": 0.6531674930336602, "strict": 0.2154696132596685}, "rouge": {"rouge1": {"precision": 0.32045520128134836, "recall": 0.7180304376195379, "fscore": 0.42300161074719367}, "rouge2": {"precision": 0.1979935998869878, "recall": 0.4389654131557785, "fscore": 0.26233077626475276}, "rougeL": {"precision": 0.2663865768311303, "recall": 0.6115257311712957, "fscore": 0.3538037743008641}}, "bleurt": 0.5081962022251187, "gpt": 0.4696132596685083, "name": "Claude 2.1", "authors": "Anthropic", "url": "https://www.anthropic.com/news/claude-2-1", "citation": "Anthropic, 2023", "type": "FOUNDATION", "context": 200000}]